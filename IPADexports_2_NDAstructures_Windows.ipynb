{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Jupyter Notebook is written to convert Raw Data and Scores files from NIH Toolbox IPAD exports into NDA data structures using linking information from a 'Crosswalk' and extra NDA-required subject identifier data (GUID, etc) from a csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Notes: \n",
    "using a specialty Python 3 virtual environment (named PycharmToolbox) as kernel for this notebook.\n",
    "Installed by running the following commands in my terminal and then switching the kernel with the dropdown menu above:\n",
    "> source /home/petra/.virtualenvs/PycharmToolbox/bin/activate\n",
    "> pip install ipykernel\n",
    "> ipython kernel install --user --name=PycharmToolbox\n",
    "> jupyter-notebook\n",
    "\n",
    "requirements file generated from within the activated virtual environment by:\n",
    "> pip freeze > requirements.txt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "snapshotdate = datetime.datetime.today().strftime('%m_%d_%Y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the input and output data and paths for NIH toolbox. \n",
    "To run the cells of this notebook, you will need four files.\n",
    "\n",
    "Two are in the .csv format of the IPAD Toolbox applcation export.\n",
    "E.g. a raw Data file containing scores for item level responses, and a Scores file, containing the summary statistics for the collection of item level data. We don't need the registration file, but it might be handy for filtering out batteries that were inappropriately administered.  These two files are linked by PIN and Inst variables, and must be cleaned a priori to remove subjects that are in one but not the other file.  I.e. the list of unique PINs (ex. HCP0211999_V1) in one file should be exactly the same as the list of unique PINs in the other. For HCP data, we concatenate the exports of all subjects' Score data in to a single file, and the exports of all subjects Raw data into a second file.  Because all other sources of HCP data use 'subject' and 'visit' rather than a PIN which is a concatenation of both, we create these variables (subject and visit) from PIN prior to running this program as well.  \n",
    "\n",
    "The third necessary file is a csv containing the fields that NDA requires in all of their structures \n",
    "e.g. subjectkey (GUID or pseudo-GUID), src_subject_id (e.g. HCP0211999), interview_age (in months), and gender (misnomer for sex assigned at birth).  In HCP data, we link the two sources of information via 'subject' and 'visit.'  \n",
    "\n",
    "Lastly, read in the crosswalk file - which will map your vars to NDA after transpose is complete.  I have placed the crosswalk from HCP data.  Any instruments in this crosswalk that are the same as yours (look at 'Inst' column) will work for you provided you haven't renamed your columns.  You will have to add any instruments not present, after obtaining variable maps and templates from the NDA for your particular set of NIH Toolbox Data.  \n",
    "\n",
    "Note that subject and visit are variables we created locally to merge with the data coming from a different local source (REDCap).  They are not variables that are output from the NIH Toolbox app on the Ipads, but are necessary for the merge with the NDA required fields stored elsewhere.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This notebook is specific to Windows formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#POINT TO YOUR DATA - a scores file and a raw file.  These will be the output from the IPAD, concatenated.  \n",
    "# E.g. take all the scores and concatenate vertically in to a single file, and take all the raw item data and \n",
    "# concatenate into a single file.  Files are linked by PIN and Instrument.  \n",
    "# In general there will be multiple row in the Raw Data file for every Instrument/PIN row in the Scores file, \n",
    "# All exceptions to this generality are accounted for below\n",
    "##########################\n",
    "\n",
    "#HCP has two different Lifespan studies going to NDA - HCP - Aging, and HCP Developement.  \n",
    "#We have a few internal aliases for these studies that need to be labelled here; \n",
    "#hcp_studystr gets passed into the functions that name the output structures (e.g. a string for the filename). \n",
    "#ndar_studystr gets passed into the argument that opens the csv that contains ALL of the HCP \n",
    "#subjects (they are related, so they have to be considered together) and subsets based on study\n",
    "\n",
    "\n",
    "##########################\n",
    "#hcp_studystr='yourstudy'\n",
    "#ndar_studystr='placeholderforastringyouprobablywontneed'\n",
    "#scoresD='pathtoyourscores/yourscores.csv'\n",
    "#rawE='pathtoyourrawdata/yourraw.csv'\n",
    "##########################\n",
    "\n",
    "#hcp_studystr='HCPD'\n",
    "#ndar_studystr='HCD'\n",
    "#scoresD='/home/petra/UbWinSharedSpace1/boxtemp/HCD_Toolbox_Scored_Combined_04_01_2020.csv'\n",
    "#rawD='/home/petra/UbWinSharedSpace1/boxtemp/HCD_Toolbox_Raw_Combined_04_01_2020.csv'\n",
    "\n",
    "##########################\n",
    "#don't have ndar_studystr for HCP-EP\n",
    "hcp_studystr='HCP-EP'\n",
    "scoresD='~\\\\path\\\\to\\\\concatenated\\\\scores\\\\Assessment_Scores_Total.csv'\n",
    "rawD='~\\\\path\\\\to\\\\concatenated\\\\raw_data\\\\Assessment_Data_Total2.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path where you want to save your formatted structures\n",
    "#note for Windows, a substituion of \"C:\\\\Users\\\\User\" with \"~\" might lead to errors in saving files later on. \n",
    "pathout=\"C:\\\\Users\\\\username\\\\path\\\\to\\\\output\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIN</th>\n",
       "      <th>DeviceID</th>\n",
       "      <th>Assessment Name</th>\n",
       "      <th>Inst</th>\n",
       "      <th>RawScore</th>\n",
       "      <th>Theta</th>\n",
       "      <th>TScore</th>\n",
       "      <th>SE</th>\n",
       "      <th>ItmCnt</th>\n",
       "      <th>DateFinished</th>\n",
       "      <th>...</th>\n",
       "      <th>Static Visual Acuity Snellen</th>\n",
       "      <th>Whole Mouth Salt</th>\n",
       "      <th>Whole Mouth Quinine</th>\n",
       "      <th>InstrumentBreakoff</th>\n",
       "      <th>InstrumentStatus2</th>\n",
       "      <th>InstrumentRCReason</th>\n",
       "      <th>InstrumentRCReasonOther</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>Unnamed: 48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>D70A411E-7F4E-46B7-9433-D68CE823BFFF</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>NIH Toolbox Picture Vocabulary Test Age 3+ v2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.512</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10/7/2016 10:01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>D70A411E-7F4E-46B7-9433-D68CE823BFFF</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>NIH Toolbox Flanker Inhibitory Control and Att...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10/7/2016 10:05</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rescored</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>D70A411E-7F4E-46B7-9433-D68CE823BFFF</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>NIH Toolbox List Sorting Working Memory Test A...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10/7/2016 10:13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rescored</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>D70A411E-7F4E-46B7-9433-D68CE823BFFF</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>NIH Toolbox Dimensional Change Card Sort Test ...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>10/7/2016 10:19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rescored</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>D70A411E-7F4E-46B7-9433-D68CE823BFFF</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>NIH Toolbox Pattern Comparison Processing Spee...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>10/7/2016 10:23</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rescored</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PIN                              DeviceID Assessment Name  \\\n",
       "0  1001  D70A411E-7F4E-46B7-9433-D68CE823BFFF      Assessment   \n",
       "1  1001  D70A411E-7F4E-46B7-9433-D68CE823BFFF      Assessment   \n",
       "2  1001  D70A411E-7F4E-46B7-9433-D68CE823BFFF      Assessment   \n",
       "3  1001  D70A411E-7F4E-46B7-9433-D68CE823BFFF      Assessment   \n",
       "4  1001  D70A411E-7F4E-46B7-9433-D68CE823BFFF      Assessment   \n",
       "\n",
       "                                                Inst  RawScore  Theta  TScore  \\\n",
       "0    NIH Toolbox Picture Vocabulary Test Age 3+ v2.0       NaN  8.046     NaN   \n",
       "1  NIH Toolbox Flanker Inhibitory Control and Att...      20.0    NaN     NaN   \n",
       "2  NIH Toolbox List Sorting Working Memory Test A...      19.0    NaN     NaN   \n",
       "3  NIH Toolbox Dimensional Change Card Sort Test ...      29.0    NaN     NaN   \n",
       "4  NIH Toolbox Pattern Comparison Processing Spee...      46.0    NaN     NaN   \n",
       "\n",
       "      SE  ItmCnt     DateFinished  ...  Static Visual Acuity Snellen  \\\n",
       "0  0.512    30.0  10/7/2016 10:01  ...                           NaN   \n",
       "1    NaN    24.0  10/7/2016 10:05  ...                           NaN   \n",
       "2    NaN    18.0  10/7/2016 10:13  ...                           NaN   \n",
       "3    NaN    38.0  10/7/2016 10:19  ...                           NaN   \n",
       "4    NaN    47.0  10/7/2016 10:23  ...                           NaN   \n",
       "\n",
       "   Whole Mouth Salt  Whole Mouth Quinine  InstrumentBreakoff  \\\n",
       "0               NaN                  NaN                 2.0   \n",
       "1               NaN                  NaN                 2.0   \n",
       "2               NaN                  NaN                 2.0   \n",
       "3               NaN                  NaN                 2.0   \n",
       "4               NaN                  NaN                 2.0   \n",
       "\n",
       "   InstrumentStatus2 InstrumentRCReason  InstrumentRCReasonOther  Unnamed: 46  \\\n",
       "0                3.0                NaN                      NaN          NaN   \n",
       "1                3.0                NaN                 rescored          NaN   \n",
       "2                3.0                NaN                 rescored          NaN   \n",
       "3                3.0                NaN                 rescored          NaN   \n",
       "4                3.0                NaN                 rescored          NaN   \n",
       "\n",
       "   Unnamed: 47  Unnamed: 48  \n",
       "0          NaN          PIN  \n",
       "1          NaN         1001  \n",
       "2          NaN         1002  \n",
       "3          NaN         1003  \n",
       "4          NaN         1004  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read into dataframe and take a peak (we alphabetized our columns during concat process)\n",
    "scordata=pd.read_csv(scoresD,header=0,low_memory=False)\n",
    "scordata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6172, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata=pd.read_csv(rawD,header=0,low_memory=False,error_bad_lines=True)\n",
    "#rawdata.head()\n",
    "rawdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PIN', 'DeviceID', 'Assessment Name', 'InstOrdr', 'InstSctn', 'ItmOrdr',\n",
       "       'Inst', 'Locale', 'ItemID', 'Response', 'Score', 'Theta', 'TScore',\n",
       "       'SE', 'DataType', 'Position', 'ResponseTime', 'DateCreated',\n",
       "       'InstStarted', 'InstEnded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just taking a look here\n",
    "rawdata.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata.PIN.unique()[0:10]\n",
    "#rawdata.groupby(['Inst','ItemID']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HCP data had some alternatives to '1 or 2' for assessment name that needed to be sent back to RAs for clarification\n",
    "#after all was said and done - set to missing here after capturing flags because\n",
    "#fneproc has limitations on character length, and need be consistent\n",
    "rawdata['Assessment Name']=rawdata['Assessment Name'].str.replace('Assessment ','')\n",
    "scordata['Assessment Name']=scordata['Assessment Name'].str.replace('Assessment ','')\n",
    "\n",
    "raw_assessment_strings=rawdata.loc[~(rawdata['Assessment Name'].isin(['1','2','3']))][['PIN','Assessment Name']].drop_duplicates(keep='first')\n",
    "score_assessment_strings=scordata.loc[~(scordata['Assessment Name'].isin(['1','2','3']))][['PIN','Assessment Name']].drop_duplicates(keep='first')\n",
    "#score_assessment_strings\n",
    "#raw_assessment_strings\n",
    "assessment_strings_forFU=pd.merge(raw_assessment_strings,score_assessment_strings,on=['PIN','Assessment Name'],how='outer',indicator=True)\n",
    "assessment_strings_forFU.loc[~(assessment_strings_forFU._merge =='both')]\n",
    "assessment_strings_forFU.drop(columns=['_merge']).to_csv(\"TLBX Records with Unexpected Assessment Strings.csv\",index=False)\n",
    "\n",
    "\n",
    "#set strings to missing\n",
    "rawdata.loc[~(rawdata['Assessment Name'].isin(['1','2','3'])),'Assessment Name']=''\n",
    "scordata.loc[~(scordata['Assessment Name'].isin(['1','2','3'])),'Assessment Name']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subjectkey', 'src_subject_id', 'interview_date', 'interview_age',\n",
       "       'gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prep the fields that NDA requires in all of their structures - we do this through a separate generator  \n",
    "#reading in the CSV and making sure the date format is NDA appropriate\n",
    "#creading list of NDA requirement variables - ndarlist\n",
    "ndarD='~\\\\path\\\\to\\\\NDA\\\\requirements\\\\NDA Prep.csv'\n",
    "ndar=pd.read_csv(ndarD,header=0,low_memory=False,error_bad_lines=True)\n",
    "ndar['interview_date'] = pd.to_datetime(ndar['interview_date']).dt.strftime('%m/%d/%Y')\n",
    "ndarlist=['subjectkey','src_subject_id','interview_age','interview_date','gender']\n",
    "ndar.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the list of variables in the scored and raw data files that you might need...\n",
    "#creating list in case your scored data is merged with other files for other reasons (ours was)\n",
    "scorlist=['Age-Corrected Standard Score', 'Age-Corrected Standard Scores Dominant',\n",
    " 'Age-Corrected Standard Scores Non-Dominant', 'AgeCorrCrystal', 'AgeCorrDCCS', 'AgeCorrEarly',\n",
    " 'AgeCorrEngRead', 'AgeCorrEngVocab', 'AgeCorrFlanker', 'AgeCorrFluid', 'AgeCorrListSort',\n",
    " 'AgeCorrPSM', 'AgeCorrPatternComp', 'AgeCorrTotal', 'Assessment Name', 'Computed Score',\n",
    " 'ComputedDCCS', 'ComputedEngRead', 'ComputedEngVocab', 'ComputedFlanker', 'ComputedPSM',\n",
    " 'ComputedPatternComp', 'DCCSaccuracy', 'DCCSreactiontime',  'Dominant Score', 'FlankerAccuracy',\n",
    " 'FlankerReactionTime', 'FullTCrystal', 'FullTDCCS', 'FullTEarly', 'FullTEngRead', 'FullTEngVocab',\n",
    " 'FullTFlanker', 'FullTFluid', 'FullTListSort', 'FullTPSM', 'FullTPatternComp', 'FullTTotal',\n",
    " 'Fully-Corrected T-score', 'Fully-Corrected T-scores Dominant', 'Fully-Corrected T-scores Non-Dominant',\n",
    " 'FullyCorrectedTscore', 'Group', 'Inst', 'InstrumentBreakoff', 'InstrumentRCReason', 'InstrumentRCReasonOther',\n",
    " 'InstrumentStatus2', 'ItmCnt', 'Language', 'Male', 'National Percentile (age adjusted)',\n",
    " 'National Percentile (age adjusted) Dominant', 'National Percentile (age adjusted) Non-Dominant',\n",
    " 'Non-Dominant Score', 'PIN', 'Raw Score Left Ear', 'Raw Score Right Ear', 'RawDCCS',\n",
    " 'RawFlanker', 'RawListSort', 'RawPSM', 'RawPatternComp', 'RawScore', 'SE', 'Static Visual Acuity Snellen',\n",
    " 'Static Visual Acuity logMAR', 'TScore', 'Theta', 'ThetaEngRead', 'ThetaEngVocab', 'ThetaPSM', 'Threshold Left Ear',\n",
    " 'Threshold Right Ear', 'UncorrCrystal', 'UncorrDCCS', 'UncorrEarly', 'UncorrEngRead', 'UncorrEngVocab',\n",
    " 'UncorrFlanker', 'UncorrFluid', 'UncorrListSort', 'UncorrPSM', 'UncorrPatternComp', 'UncorrTotal',\n",
    " 'Uncorrected Standard Score', 'Uncorrected Standard Scores Dominant', 'Uncorrected Standard Scores Non-Dominant',\n",
    " 'UncorrectedStandardScore']\n",
    "rawlist=['App Version', 'Assessment Name', 'DataType','DateCreated', 'DeviceID',  'Firmware Version',  \n",
    " 'Inst', 'InstEnded','InstEndedDatetime', 'InstOrdr', 'InstSctn', 'InstStarted','InstStartedDatetime',\n",
    " 'ItemID', 'ItmOrdr', 'Locale','PIN', 'Position', 'Response', 'ResponseTime', 'SE', 'Score', 'TScore',\n",
    " 'Theta','iPad Version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HCP-EP Note: list of variables from Scores and Raw that we actually have in our data\n",
    "#if lists don't match (i.e. if scorlist has variables your Scores data does not, error will occur in the next merge step)\n",
    "#list copied from output of 'rawdata.columns' and 'scordata.columns'\n",
    "scorlist=['PIN', 'DeviceID', 'Assessment Name', 'Inst', 'RawScore', 'Theta',\n",
    "       'TScore', 'SE', 'ItmCnt', 'DateFinished', 'Column1', 'Column2',\n",
    "       'Column3', 'Column4', 'Column5', 'Language', 'Computed Score',\n",
    "       'Uncorrected Standard Score', 'Age-Corrected Standard Score',\n",
    "       'Fully-Corrected T-score', 'Uncorrected Standard Scores Dominant',\n",
    "       'Age-Corrected Standard Scores Dominant',\n",
    "       'Fully-Corrected T-scores Dominant',\n",
    "       'Uncorrected Standard Scores Non-Dominant',\n",
    "       'Age-Corrected Standard Scores Non-Dominant',\n",
    "       'Fully-Corrected T-scores Non-Dominant',\n",
    "       'Uncorrected Standard Scores Quinine Whole',\n",
    "       'Uncorrected Standard Scores Salt Whole',\n",
    "       'Age-Corrected Standard Scores Quinine Whole',\n",
    "       'Age-Corrected Standard Scores Salt Whole',\n",
    "       'Fully-Corrected T-scores Quinine Whole',\n",
    "       'Fully-Corrected T-scores Salt Whole', 'Dominant Score',\n",
    "       'Non-Dominant Score', 'Raw Score Right Ear', 'Threshold Right Ear',\n",
    "       'Raw Score Left Ear', 'Threshold Left Ear',\n",
    "       'Static Visual Acuity logMAR', 'Static Visual Acuity Snellen',\n",
    "       'Whole Mouth Salt', 'Whole Mouth Quinine', 'InstrumentBreakoff',\n",
    "       'InstrumentStatus2', 'InstrumentRCReason', 'InstrumentRCReasonOther']\n",
    "rawlist=['PIN', 'DeviceID', 'Assessment Name', 'InstOrdr', 'InstSctn', 'ItmOrdr',\n",
    "       'Inst', 'Locale', 'ItemID', 'Response', 'Score', 'Theta', 'TScore',\n",
    "       'SE', 'DataType', 'Position', 'ResponseTime', 'DateCreated',\n",
    "       'InstStarted', 'InstEnded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the score and raw data with the required fields for the NDA\n",
    "#Note that subject and visit are HCP specific variables that we use to subset the records being sent to the NDA\n",
    "#Depending on how you organized your data, you may need to create dummy vars if you dont have them...\n",
    "#for HCP-EP, still unclear how FU data will be released out\n",
    "scordata['subject']=scordata.PIN #or some other variable in scordata that can be used to merge with ndarfields data\n",
    "scordata['visit']='V1' #we keep this around because eventually we'll be releaseing V2,V3, and FU data\n",
    "rawdata['subject']=rawdata.PIN\n",
    "rawdata['visit']='V1'\n",
    "\n",
    "#if you did not create 'scorlist' or 'rawlist' in the previous steps, run the following lines instead\n",
    "#scordata=pd.merge(scordata,ndar,how='inner',left_on='subject', right_on='src_subject_id')\n",
    "#rawdata=pd.merge(rawdata,ndar,how='inner',left_on='subject', right_on='src_subject_id')\n",
    "scordata=pd.merge(scordata[scorlist+['subject','visit']],ndar,how='inner',left_on='subject', right_on='src_subject_id')\n",
    "rawdata=pd.merge(rawdata[rawlist+['subject','visit']],ndar,how='inner',left_on='subject', right_on='src_subject_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a little QC and data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Instruments in Raw data but not Scores:\n",
      "NIH Toolbox Picture Vocabulary Test Age 3+ Practice v2.0\n",
      "NIH Toolbox Pattern Comparison Processing Speed Test Age 7+ Practice v2.1\n",
      "NIH Toolbox Pain Intensity FF Age 18+ v2.0\n",
      "******Instruments in Scored data but not Raw:\n",
      "Cognition Fluid Composite v1.1\n",
      "Cognition Crystallized Composite v1.1\n",
      "Cognition Total Composite Score v1.1\n",
      "Cognition Early Childhood Composite v1.1\n",
      "Negative Affect Summary (18+)\n",
      "Social Satisfaction Summary (18+)\n",
      "Psychological Well Being Summary (18+)\n",
      "NIH Toolbox Visual Acuity Practice Age 8+ v2.0\n"
     ]
    }
   ],
   "source": [
    "#NOW that you have ALL of your data, take a look at how the intruments are organized within them.  \n",
    "#for example, the bulk of instruments have representation in the raw files AND the scored files, and can be \n",
    "#handled by the 'normal' code block below.  We will need to code for exceptions, though. \n",
    "#All code blocks below will skip Practice instruments and Instructions\n",
    "\n",
    "print('*****Instruments in Raw data but not Scores:')\n",
    "for i in rawdata.Inst.unique():\n",
    "    if i not in scordata.Inst.unique():\n",
    "        print(i)\n",
    "print('******Instruments in Scored data but not Raw:')\n",
    "for i in scordata.Inst.unique():\n",
    "    if i not in rawdata.Inst.unique():\n",
    "        print(i)\n",
    "\n",
    "#Occasionally one of the instruments, (NIH Toolbox List Sorting Working Memory Test Ages 3-6 v2.1 in our case) will showing up for protocol\n",
    "#deviation reasons (someone opened and closed a battery, for example).  The validated column of the crosswalk has been set to NO \n",
    "# for this instrument, but you may have the item level info to extend and validate htis in your data.  \n",
    "#nan rows in Raw data can correspond to cases where Registration Data was uploaded as 'raw' data and concatenated behind the scenes somewhere.  \n",
    "#you will need to QC (we just allow program to drop them here - send flag back to your data curation team for next release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n",
      "(6172, 27)\n",
      "(601, 53)\n",
      "(6172, 27)\n",
      "(601, 53)\n"
     ]
    }
   ],
   "source": [
    "#check that lengths are the same...indicating one to one PIN match between scores and raw\n",
    "print(len(rawdata.PIN.unique()))\n",
    "print(len(scordata.PIN.unique()))\n",
    "#check that shape is same before and after removing duplicates (should not be any)\n",
    "rawdata.shape\n",
    "scordata.shape\n",
    "print(rawdata.shape)\n",
    "print(scordata.shape)\n",
    "testraw=rawdata.drop_duplicates(subset={'PIN','Inst','ItemID','Position'},keep='first')\n",
    "testscore=scordata.drop_duplicates(subset={'PIN','Inst'})\n",
    "print(testraw.shape)\n",
    "print(testscore.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function that will turn a prepared (e.g already transformed, renamed, revalued, etc. and otherwise\n",
    "# ready to go) dataframe into a csv structure \n",
    "def data2struct(patho,dout,crosssub,study):\n",
    "    \"\"\"\n",
    "    Convert dout, a prepared pandas dataframe, into a csv structure that NDA can import\n",
    "    \n",
    "    parameters: \n",
    "    patho - full path to place you want to store structures (there will be many)\n",
    "    dout - name of data frame that contains all the variables to be exported\n",
    "    crosssub - a dataframe which is the subset of the crosswalk for the instrument to be exported as structure\n",
    "    study - a string to put in the name of the csv file along with the structure name and the short name of the instrument\n",
    "    \n",
    "    note that snapshotdate is globally defined external to this funtion near import statments...     \n",
    "    \n",
    "    \"\"\"\n",
    "    #get the name and number of the structure from the crosswalk subset\n",
    "    strucroot=crosssub['nda_structure'].str.strip().str[:-2][0]\n",
    "    strucnum=crosssub['nda_structure'].str.strip().str[-2:][0]\n",
    "    #prepare the name of the output file and path\n",
    "    instshort=crosssub['inst_short'].str.strip()[0]\n",
    "    inst=crosssub['Inst'].str.strip()[0].replace(' ','_').replace('+','plus').replace('-','_') \n",
    "    filePath=os.path.join(pathout,study+'_'+instshort+'_'+strucroot+strucnum+'_'+snapshotdate+'.csv')\n",
    "    if os.path.exists(filePath):\n",
    "        os.remove(filePath)\n",
    "    else:\n",
    "        pass\n",
    "        #print(\"Can not delete the file as it doesn't exists\")\n",
    "    with open(filePath,'a') as f:\n",
    "        f.write(strucroot+\",\"+str(int(strucnum))+\"\\n\")\n",
    "        dout.to_csv(f,index=False,line_terminator='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function sends a transformed dataframe of the right 'shape' (i.e. after items have been pivoted into row with scores)\n",
    "# through the crosswalk for renaming, revaluing and structure destination mapping\n",
    "#function takes a dataframe (in which NIH Toolbox Items are still the names) and formats the column names \n",
    "#such that all the special characters are removed because the export has characters that python and the NDA dont like\n",
    "#This function will alert you to any instruments that were successfully transformed but tha might\n",
    "#warrent a closer look.\n",
    "\n",
    "def sendthroughcrosswalk(pathout,instreshapedfull,inst_i,crosswalk,studystr,verbose,debug):\n",
    "    \"\"\"\n",
    "    Send instreshapedfull, a dataframe that has pivoted the item level data into the scored data by instrument\n",
    "    through the crosswalk to have its variables renamed and reformatted according to the harmonization \n",
    "    requests of the NDA\n",
    "    \n",
    "    parameters: \n",
    "    pathout - full path to place you want to store structures (there will be many) - argument gets passed to data2struct fuctnion\n",
    "    inst_i - string name of instrument as it appears in the NIH Toolbox output, exactly (case sensitive with version)\n",
    "    crosswalk - pandas dataframe of crosswalk (read from csv)\n",
    "    studystr - 'HCPA' or other string specified at the beginning of this notebook - will be passed to data2struct funciton to tag the file\n",
    "               name with the study source of the data\n",
    "    verbose - YES or NO, will flag all the variable to element mappings available in the crosswalk \n",
    "              that weren't called upon in this transformation because they weren't found in your data\n",
    "    debug - YES or NO, will print out the last row to be executed from the 'requested_python' column, in case you get an \n",
    "            Error, and need to figure out where the loop got stuck\n",
    "    \"\"\"\n",
    "    # replace special charaters in column names\n",
    "    instreshapedfull.columns = instreshapedfull.columns.str.replace(' ', '_').str.replace('-', '_').str.replace('(','_').str.replace(')', '_')\n",
    "    crosswalk_subset = crosswalk.loc[crosswalk['Inst'] == inst_i]\n",
    "    crosswalk_subset.reset_index(inplace=True)\n",
    "    #\n",
    "    if crosswalk_subset.reset_index().validated[0]=='NO':\n",
    "            print(\"Skipping \"+inst_i+ \" because crosswalk not yet validated for this instrument \")\n",
    "    else: \n",
    "        # some studies will have some but not all of the variables in hcp_variable (result of skip logic, perhaps)\n",
    "        # need to make sure they know about this(in case not due to skip logic) but also that code is only execute for\n",
    "        # vars in existence.  \n",
    "        #also need to keep track of dummy vars that dont exist in IPAD output, but are necessary for NDA and need to be created \n",
    "        #on the fly\n",
    "        #how many vars are in the instrument according to what is stored in hcp_variable? \n",
    "        cwlistbef = list(crosswalk_subset['hcp_variable'])\n",
    "        before = len(cwlistbef)\n",
    "        #how many are in the intersection of hcp_variable and the prepared data (e.g. what shows up with the particular instrument in instreshapedfull)\n",
    "        cwlist = list(set(cwlistbef) & set(\n",
    "            instreshapedfull.columns))  # drop the handful of vars in larger instruments that got mapped but that we dont have\n",
    "        after = len(cwlist)\n",
    "        if before != after:\n",
    "            print(\"WARNING!!! \" + inst_i + \": Crosswalk expects \" + str(before) + \" elements, but only found \" + str(after)+ \" in the prepared data\")\n",
    "            notfound=list(np.setdiff1d(cwlistbef,cwlist))\n",
    "            if verbose=='YES':\n",
    "                print(\"Not Found:\"+ str(notfound))\n",
    "        #get the dummies\n",
    "        dummys=[]\n",
    "        for i in cwlistbef:\n",
    "            if \"dummy\" in i:\n",
    "                dummys=dummys+[i]\n",
    "        #studydata should have all the ndar variables and the list of vars in the intersection of what exists in ipad output and\n",
    "        #what can be received per the crosswalk.  \n",
    "        # if you dont force the intersection then code will try to execute on things that dont exist\n",
    "        #The new dummy variables will be created on the fly.\n",
    "        studydata = instreshapedfull[ndarlist + cwlist].copy()\n",
    "        # execute any python one liners (see how they all refer to studydata?) for all rows in the crosswalk corresponding to cwlist this instrument vars except the notfounds.\n",
    "        itersubset=crosswalk_subset.loc[crosswalk_subset.hcp_variable.isin(cwlist + dummys)]\n",
    "        for index, row in itersubset.iterrows():#crosswalk_subset.iterrows():\n",
    "            if pd.isna(row['requested_python']):\n",
    "                pass\n",
    "            else:\n",
    "                if debug=='YES':\n",
    "                    print(row['requested_python'])\n",
    "                exec(row['requested_python'])\n",
    "        uploadlist = list(crosswalk_subset['hcp_variable_upload'])\n",
    "        uploadlist = list(set(uploadlist) & set(studydata.columns))\n",
    "        data2struct(patho=pathout, dout=studydata[ndarlist + uploadlist], crosssub=crosswalk_subset, study=studystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validated</th>\n",
       "      <th>Measurement System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Item ID</th>\n",
       "      <th>Stem</th>\n",
       "      <th>Context</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Responses</th>\n",
       "      <th>Inst</th>\n",
       "      <th>hcp_variable</th>\n",
       "      <th>...</th>\n",
       "      <th>specialty_code</th>\n",
       "      <th>hcp_variable_upload</th>\n",
       "      <th>nda_structure</th>\n",
       "      <th>nda_element</th>\n",
       "      <th>description</th>\n",
       "      <th>valueRange</th>\n",
       "      <th>notes</th>\n",
       "      <th>template</th>\n",
       "      <th>inst_short</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anxiety Summary Parent Report (3-7)</td>\n",
       "      <td>Inst</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>version_form</td>\n",
       "      <td>tlbx_fearanx01</td>\n",
       "      <td>version_form</td>\n",
       "      <td>Form used/assessment name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anxiety_Summary_3-7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anxiety Summary Parent Report (3-7)</td>\n",
       "      <td>Assessment_Name</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fneproc</td>\n",
       "      <td>tlbx_fearanx01</td>\n",
       "      <td>fneproc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anxiety_Summary_3-7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anxiety Summary Parent Report (3-7)</td>\n",
       "      <td>respondent</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comqother</td>\n",
       "      <td>tlbx_fearanx01</td>\n",
       "      <td>comqother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anxiety_Summary_3-7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anxiety Summary Parent Report (3-7)</td>\n",
       "      <td>Fully_Corrected_T_score</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nih_tlbx_fctsc</td>\n",
       "      <td>tlbx_fearanx01</td>\n",
       "      <td>nih_tlbx_fctsc</td>\n",
       "      <td>Fully-Corrected T-Score</td>\n",
       "      <td>0::120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anxiety_Summary_3-7.tlbx_fearanx01_template</td>\n",
       "      <td>Anxiety_Summary_3-7</td>\n",
       "      <td>HCPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anxiety Summary Parent Report (3-7)</td>\n",
       "      <td>Language</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>primary_language</td>\n",
       "      <td>tlbx_fearanx01</td>\n",
       "      <td>primary_language</td>\n",
       "      <td>Subject's Primary Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anxiety_Summary_3-7.tlbx_fearanx01_template</td>\n",
       "      <td>Anxiety_Summary_3-7</td>\n",
       "      <td>HCPD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  validated Measurement System Domain Item ID Stem Context DataType Responses  \\\n",
       "0       NaN                NaN    NaN     NaN  NaN     NaN      NaN       NaN   \n",
       "1       NaN                NaN    NaN     NaN  NaN     NaN      NaN       NaN   \n",
       "2       NaN                NaN    NaN     NaN  NaN     NaN      NaN       NaN   \n",
       "3       NaN                NaN    NaN     NaN  NaN     NaN      NaN       NaN   \n",
       "4       NaN                NaN    NaN     NaN  NaN     NaN      NaN       NaN   \n",
       "\n",
       "                                  Inst             hcp_variable  ...  \\\n",
       "0  Anxiety Summary Parent Report (3-7)                     Inst  ...   \n",
       "1  Anxiety Summary Parent Report (3-7)          Assessment_Name  ...   \n",
       "2  Anxiety Summary Parent Report (3-7)               respondent  ...   \n",
       "3  Anxiety Summary Parent Report (3-7)  Fully_Corrected_T_score  ...   \n",
       "4  Anxiety Summary Parent Report (3-7)                 Language  ...   \n",
       "\n",
       "  specialty_code hcp_variable_upload   nda_structure       nda_element  \\\n",
       "0            NaN        version_form  tlbx_fearanx01      version_form   \n",
       "1            NaN             fneproc  tlbx_fearanx01           fneproc   \n",
       "2            NaN           comqother  tlbx_fearanx01         comqother   \n",
       "3            NaN      nih_tlbx_fctsc  tlbx_fearanx01    nih_tlbx_fctsc   \n",
       "4            NaN    primary_language  tlbx_fearanx01  primary_language   \n",
       "\n",
       "                  description valueRange notes  \\\n",
       "0   Form used/assessment name        NaN   NaN   \n",
       "1                         NaN        NaN   NaN   \n",
       "2                         NaN        NaN   NaN   \n",
       "3     Fully-Corrected T-Score     0::120   NaN   \n",
       "4  Subject's Primary Language        NaN   NaN   \n",
       "\n",
       "                                      template           inst_short Source  \n",
       "0                                          NaN  Anxiety_Summary_3-7    NaN  \n",
       "1                                          NaN  Anxiety_Summary_3-7    NaN  \n",
       "2                                          NaN  Anxiety_Summary_3-7    NaN  \n",
       "3  Anxiety_Summary_3-7.tlbx_fearanx01_template  Anxiety_Summary_3-7   HCPD  \n",
       "4  Anxiety_Summary_3-7.tlbx_fearanx01_template  Anxiety_Summary_3-7   HCPD  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specify your crosswalk- take a peak - use the latest crosswalk from the https://github.com/humanconnectome/NIHToolbox2NDA/\n",
    "#e.g. Crosswalk_NIH_Toolbox_2_NDA.csv\n",
    "crosswalkpath=\"~\\\\path\\\\to\\\\directory\\\\with\\\\crosswalk\\\\\"\n",
    "cfile=\"Crosswalk_NIH_Toolbox_2_NDA.csv\"\n",
    "crosswalk=pd.read_csv(crosswalkpath+cfile,header=0,low_memory=False, encoding = \"ISO-8859-1\")\n",
    "crosswalk.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping NIH Toolbox Picture Sequence Memory Test Age 8+ Form A v2.1 because crosswalk not yet validated for this instrument \n",
      "Skipping NIH Toolbox Words-In-Noise Test Age 6+ v2.1 because crosswalk not yet validated for this instrument \n",
      "Note:  Omitting practice instrument, NIH Toolbox Visual Acuity Practice Age 8+ v2.0\n",
      "WARNING!!! NIH Toolbox Visual Acuity Test Age 8+ v2.0: Crosswalk expects 112 elements, but only found 11 in the prepared data\n",
      "studydata['nih_tlbx_agegencsc']='999'\n",
      "studydata['nih_tlbx_rawscore']='999'\n",
      "studydata['nih_tlbx_se']='999'\n",
      "studydata['nih_tlbx_theta']='999'\n",
      "studydata['nih_tlbx_tscore']='999'\n",
      "studydata['age_corrected_standard_score']=studydata['Age_Corrected_Standard_Score'].fillna(-9999).astype(int).astype(str).str.replace('-9999','')\n",
      "studydata['nih_tlbx_fctsc']=studydata['Fully_Corrected_T_score']\n",
      "studydata['version_form']=studydata['Inst']\n",
      "studydata['fneproc']=studydata['Assessment_Name'].str.replace('Assessment ','')\n",
      "studydata['comqother']=studydata['respondent']\n",
      "studydata['wcst_ni']=studydata.ItmCnt.round().fillna(-9999).astype(int).astype(str).str.replace('-9999','')\n",
      "studydata['interview_language']=studydata['Language']\n",
      "studydata['raw_vat']=studydata['RawScore'].fillna(-9999).astype(int).astype(str).str.replace('-9999','')\n",
      "studydata['staticvalogmar']=studydata['Static_Visual_Acuity_logMAR']\n",
      "studydata['vbdva_stattestscore']=studydata['Uncorrected_Standard_Score'].fillna(-9999).astype(int).astype(str).str.replace('-9999','')\n"
     ]
    }
   ],
   "source": [
    "# For some instruments we only want to send scores.  See discussion about Visual Acuity Instruements below, for example. \n",
    "# For other instruments we only CAN send scores, \n",
    "# one reason is that only score level data is avaialbe for this instrument (see next code cell)\n",
    "# Other reason is because only score level data is ready to go (item level data not yet mapped at the NDA)\n",
    "# for example, the Picture Sequence instruments...NIH Data dictionary wasn't sufficient to \n",
    "# map the item level data to the NDA, where items are incorrect/correct but NIH Toolbox outputting value range of\n",
    "# 0::14. Item level detail for this particular instrument will require facilitation between NIH Toolbox and NDA to define\n",
    "# new variables for these particular items (not done yet). Similar story for Words-In-Noise, where data dictionar at both ends\n",
    "# (NIH Toolbox and NDA expectation) doesn't match the observed output.  Yay.  \n",
    "#When it is done, remove the elif statement from the non-special \n",
    "# cases cell block below\n",
    "# Note also you'll get a lot of warnings for these because you're only sending scores when items are also (almost) available\n",
    "scoresonly=scordata.loc[(scordata.Inst.str.contains('Visual Acuity')==True) | (scordata.Inst.str.contains('Picture Sequence Memory Test')==True)| (scordata.Inst.str.contains('Words-In-Noise')==True)]\n",
    "for i in scoresonly.Inst.unique():\n",
    "    inst_i=i\n",
    "    if \"Practice\" in inst_i:\n",
    "        print(\"Note:  Omitting practice instrument, \"+inst_i)\n",
    "    else:    \n",
    "        try:  #this will fail if there are duplicates or if no-one has the data of interest (e.g. idlist too small), or if only V2 instrument\n",
    "            #print('Processing '+inst_i+'...')\n",
    "            instreshapedfull=scordata.loc[scordata.Inst==inst_i][scorlist+ndarlist]\n",
    "            instreshapedfull['version_monster']=instreshapedfull['Inst']+','+instreshapedfull['Assessment Name']\n",
    "            #verbose will tell you which items were not found, debug will print out the python lines before they are executed\n",
    "            if 'Parent' in inst_i:\n",
    "                instreshapedfull['respondent']='parent'\n",
    "            else:\n",
    "                instreshapedfull['respondent']='self'\n",
    "            sendthroughcrosswalk(pathout,instreshapedfull, inst_i, crosswalk,studystr=hcp_studystr,verbose='NO',debug='YES')\n",
    "        except:\n",
    "            print('Couldnt process '+inst_i+'...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do special cases last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING!!! Negative Affect Summary (18+): Crosswalk expects 8 elements, but only found 5 in the prepared data\n",
      "Not Found:['dummy_00001', 'dummy_00002', 'dummy_00003']\n",
      "WARNING!!! Psychological Well Being Summary (18+): Crosswalk expects 8 elements, but only found 5 in the prepared data\n",
      "Not Found:['dummy_00035', 'dummy_00036', 'dummy_00037']\n",
      "Note:  Omitting practice instrument, NIH Toolbox Visual Acuity Practice Age 8+ v2.0\n"
     ]
    }
   ],
   "source": [
    "#For cases where instrument is in the scored data but not the raw data, e.g. \n",
    "# because this is a summary across instruments, is instructions/practice or because someone \n",
    "# opened and closes a battery before generating any item level data \n",
    "\n",
    "for i in scordata.Inst.unique():\n",
    "    if i not in rawdata.Inst.unique():\n",
    "        inst_i=i\n",
    "        if \"Cognition\" in inst_i:\n",
    "            pass  #special case--see specialty code block below\n",
    "        elif \"Practice\" in inst_i:\n",
    "            print(\"Note:  Omitting practice instrument, \"+inst_i)\n",
    "        elif \"Instructions\" in inst_i:\n",
    "            print(\"Note:  Omitting Instructions instrument, \"+inst_i)\n",
    "        else:\n",
    "            try:  #this will fail if there are duplicates or if no-one has the data of interest (e.g. idlist too small), or if only V2 instrument\n",
    "                #print('Processing '+inst_i+'...')\n",
    "                instreshapedfull=scordata.loc[scordata.Inst==inst_i][scorlist+ndarlist]\n",
    "                instreshapedfull['version_monster']=instreshapedfull['Inst']+','+instreshapedfull['Assessment Name']\n",
    "                #verbose will tell you which items were not found, debug will print out the python lines before they are executed\n",
    "                if 'Parent' in inst_i:\n",
    "                    instreshapedfull['respondent']='parent'\n",
    "                else:\n",
    "                    instreshapedfull['respondent']='self'\n",
    "                sendthroughcrosswalk(pathout,instreshapedfull, inst_i, crosswalk,studystr=hcp_studystr,verbose='YES',debug='No')\n",
    "            except:\n",
    "                print('Couldnt process '+inst_i+'...')\n",
    "\n",
    "#Lots of dummy variables were needed to fit the IPAD data into the NDA structures without needing a special code block for everye\n",
    "#single structure (see cogcomp01 specialty code below).  The reason for this is that many of these summary scores were coming \n",
    "#from different instruments before the instruments (NIH Toolbox term) were defined and versione and merged into the \n",
    "#same structure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING!!! NIH Toolbox Picture Vocabulary Test Age 3+ v2.0: Crosswalk expects 252 elements, but only found 178 in the prepared data\n",
      "Not Found:['National_Percentile__age_adjusted_', 'lavoc091', 'lavoc120', 'lavoc130', 'lavoc145', 'lavoc161', 'lavoc166', 'lavoc168', 'lavoc171', 'lavoc172', 'lavoc180', 'lavoc187', 'lavoc188', 'lavoc189', 'lavoc190', 'lavoc191', 'lavoc194', 'lavoc199', 'lavoc206', 'lavoc210', 'lavoc214', 'lavoc215', 'lavoc217', 'lavoc220', 'lavoc221', 'lavoc224', 'lavoc225', 'lavoc227', 'lavoc234', 'lavoc237', 'lavoc240', 'lavoc241', 'lavoc242', 'lavoc249', 'lavoc255', 'lavoc259', 'lavoc261', 'lavoc271', 'lavoc277', 'lavoc278', 'lavoc292', 'lavoc297', 'lavoc303', 'lavoc320', 'lavoc329', 'lavoc330', 'lavoc331', 'lavoc332', 'lavoc341', 'lavoc342', 'lavoc355', 'lavoc364', 'lavoc369', 'lavoc372', 'lavoc377', 'lavoc382', 'lavoc386', 'lavoc389', 'lavoc400', 'lavoc414', 'lavoc416', 'lavoc422', 'lavoc427', 'lavoc452', 'lavoc469', 'lavoc480', 'lavoc532', 'lavoc550', 'lavoc556', 'lavoc568', 'lavoc572', 'lavoc581', 'lavoc603', 'lavoc608']\n",
      "WARNING!!! NIH Toolbox Flanker Inhibitory Control and Attention Test Age 12+ v2.1: Crosswalk expects 38 elements, but only found 33 in the prepared data\n",
      "Not Found:['National_Percentile__age_adjusted_', 'flanker_arrow_prac5', 'flanker_arrow_prac6', 'flanker_arrow_prac7', 'flanker_arrow_prac8']\n",
      "WARNING!!! NIH Toolbox List Sorting Working Memory Test Age 7+ v2.1: Crosswalk expects 37 elements, but only found 32 in the prepared data\n",
      "Not Found:['National_Percentile__age_adjusted_', 'wmls1l2t1', 'wmls1l4t3', 'wmls2l03t3', 'wmls2l04t1']\n",
      "WARNING!!! NIH Toolbox Dimensional Change Card Sort Test Age 12+ v2.1: Crosswalk expects 52 elements, but only found 47 in the prepared data\n",
      "Not Found:['National_Percentile__age_adjusted_', 'dccs_color_prac5', 'dccs_color_prac6', 'dccs_color_prac7', 'dccs_color_prac8']\n",
      "Skipping NIH Toolbox Pattern Comparison Processing Speed Test Age 7+ v2.1 because crosswalk not yet validated for this instrument \n",
      "Note:  Sent Scores only for NIH Toolbox Picture Sequence Memory Test Age 8+ Form A v2.1\n",
      "WARNING!!! NIH Toolbox Oral Reading Recognition Test Age 3+ v2.0: Crosswalk expects 230 elements, but only found 180 in the prepared data\n",
      "Not Found:['National_Percentile__age_adjusted_', 'lare040', 'lare041', 'lare043', 'lare050', 'lare051', 'lare052', 'lare053', 'lare055', 'lare057', 'lare059', 'lare064', 'lare065', 'lare066', 'lare067', 'lare068', 'lare069', 'lare073', 'lare074', 'lare077', 'lare080', 'lare081', 'lare084', 'lare087', 'lare092', 'lare098', 'lare099', 'lare104', 'lare105', 'lare109', 'lare115', 'lare117', 'lare125', 'lare126', 'lare138', 'lare139', 'lare141', 'lare143', 'lare154', 'lare155', 'lare158', 'lare160', 'lare164', 'lare188', 'lare190', 'lare194', 'lare199', 'lare234', 'lare252', 'lare266']\n",
      "WARNING!!! NIH Toolbox 9-Hole Pegboard Dexterity Test Age 3+ v2.0: Crosswalk expects 15 elements, but only found 13 in the prepared data\n",
      "Not Found:['National_Percentile__age_adjusted__Dominant', 'National_Percentile__age_adjusted__Non_Dominant']\n",
      "WARNING!!! NIH Toolbox Grip Strength Test Age 3+ v2.0: Crosswalk expects 15 elements, but only found 13 in the prepared data\n",
      "Not Found:['National_Percentile__age_adjusted__Dominant', 'National_Percentile__age_adjusted__Non_Dominant']\n",
      "WARNING!!! NIH Toolbox 2-Minute Walk Endurance Test Age 3+ v2.0: Crosswalk expects 13 elements, but only found 12 in the prepared data\n",
      "Not Found:['National_Percentile__age_adjusted_']\n",
      "WARNING!!! NIH Toolbox Positive Affect CAT Age 18+ v2.0: Crosswalk expects 30 elements, but only found 24 in the prepared data\n",
      "Not Found:['dummy_00018', 'dummy_00019', 'pa018', 'pa030', 'pa032', 'pa044']\n",
      "WARNING!!! NIH Toolbox Meaning and Purpose CAT Age 18+ v2.0: Crosswalk expects 25 elements, but only found 24 in the prepared data\n",
      "Not Found:['pa076']\n",
      "WARNING!!! NIH Toolbox Perceived Stress FF Age 18+ v2.0: Crosswalk expects 21 elements, but only found 19 in the prepared data\n",
      "Not Found:['dummy_00016', 'dummy_00017']\n",
      "WARNING!!! NIH Toolbox Fear-Affect CAT Age 18+ v2.0: Crosswalk expects 38 elements, but only found 23 in the prepared data\n",
      "Not Found:['anxiety37', 'anxiety38', 'anxiety41', 'anxiety43', 'anxiety44', 'anxiety45', 'anxiety46', 'anxiety48', 'anxiety49', 'anxiety50', 'anxiety52', 'anxiety53', 'anxiety56', 'anxiety60', 'anxiety64']\n",
      "WARNING!!! NIH Toolbox Sadness CAT Age 18+ v2.0: Crosswalk expects 37 elements, but only found 26 in the prepared data\n",
      "Not Found:['depression31', 'depression33', 'depression34', 'depression35', 'depression37', 'depression42', 'depression49', 'depression51', 'depression52', 'depression53', 'depression55']\n",
      "WARNING!!! NIH Toolbox Anger-Affect CAT Age 18+ v2.0: Crosswalk expects 31 elements, but only found 28 in the prepared data\n",
      "Not Found:['anger32', 'anger44', 'anger52']\n",
      "WARNING!!! NIH Toolbox Pain Interference CAT Age 18+ v2.0: Crosswalk expects 27 elements, but only found 23 in the prepared data\n",
      "Not Found:['dummy_00013', 'dummy_00014', 'dummy_00015', 'painin13']\n",
      "WARNING!!! NIH Toolbox Odor Identification Test Age 10+ v2.0: Crosswalk expects 22 elements, but only found 18 in the prepared data\n",
      "Not Found:['National_Percentile__age_adjusted_', 'dummy_00005', 'dummy_00006', 'dummy_00007']\n",
      "Note:  Sent Scores only for NIH Toolbox Words-In-Noise Test Age 6+ v2.1\n",
      "ERROR: Couldnt process NIH Toolbox Regional Taste Test 12+ v2.0...\n"
     ]
    }
   ],
   "source": [
    "#for non-special instruments in both scores AND raw data types (skip the scoresonly ones from above)\n",
    "#add a check to make sure that everything found in the data has a row in the crosswalk\n",
    "#add indicator for whether this is a variable from the scores file or a variable from the raw data file.\n",
    "for i in scordata.Inst.unique():\n",
    "    if i in rawdata.Inst.unique():\n",
    "        inst_i=i\n",
    "        if \"Visual Acuity\" in inst_i:\n",
    "            pass  #special case--see below\n",
    "        elif \"Practice\" in inst_i:\n",
    "            print(\"Note:  Omitting practice instrument, \"+inst_i)\n",
    "        #new elif statements here needed because of unresolved discrepancey between NIH Data Dictionary and observed output\n",
    "        elif \"Picture Sequence Memory Test\" in inst_i:\n",
    "            print(\"Note:  Sent Scores only for \"+inst_i)\n",
    "        elif \"Words-In-Noise\" in inst_i:\n",
    "            print(\"Note:  Sent Scores only for \"+inst_i)\n",
    "        else:\n",
    "            try:  #this will fail if there are duplicates or if no-one has the data of interest (e.g. idlist too small), or if only V2 instrument\n",
    "                #print('Processing '+inst_i+'...')\n",
    "                items=rawdata.loc[rawdata.Inst==inst_i][['PIN','subject','Inst','visit','ItemID','Position',\n",
    "                   'subjectkey','src_subject_id','interview_age','interview_date','gender',\n",
    "                   'Score','Response','ResponseTime']]# not these..., 'SE', 'Response', 'TScore','Theta']]\n",
    "                items.ItemID = items.ItemID.str.lower().str.replace('-','_').str.replace('(','_').str.replace(')','_').str.replace(' ','_')\n",
    "                inst=items.pivot(index='PIN',columns='ItemID',values='Score').reset_index()\n",
    "                meta=items.drop_duplicates(subset=['PIN','visit'])\n",
    "                instreshaped = pd.merge(meta, inst, on='PIN', how='inner').drop(columns={'subject', 'visit','Inst'})\n",
    "                items2=scordata.loc[scordata.Inst==inst_i][scorlist]\n",
    "                instreshapedfull=pd.merge(instreshaped,items2,on='PIN',how='inner')\n",
    "                instreshapedfull['version_monster']=instreshapedfull['Inst']+','+instreshapedfull['Assessment Name']\n",
    "                #verbose will tell you which items were not found, debug will print out the python lines before they are executed\n",
    "                if 'Parent' in inst_i:\n",
    "                    instreshapedfull['respondent']='parent'\n",
    "                else:\n",
    "                    instreshapedfull['respondent']='self'\n",
    "                sendthroughcrosswalk(pathout,instreshapedfull, inst_i, crosswalk,studystr=hcp_studystr,verbose='YES',debug='NO')\n",
    "            except:\n",
    "                print('ERROR: Couldnt process '+inst_i+'...')\n",
    "\n",
    "# NOTE: its okay if there are items in the crosswalk that doent exist in your data...lots of reasons\n",
    "# not okay if there are scores in the crosswalk that doent exsit in the data...need to investigate\n",
    "# also will be flags for dummy vars because they exist in crosswalk but not data (they were created for the NDA)\n",
    "# turn verbose off to ignore these warnings.  Errors will still be reported.\n",
    "# for instruments not validated--check crosswalk. v2.1 of some isntruments dont exist in the NIH Toolbox Data\n",
    "# Dictionary yet, so its pointless to try to pretend that we know what they map to in the NDA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#special coding required for instruments in the crosswalk that have jupyter in their specialty code columns\n",
    "#Within the rawdata structure (for HCP), all but the NIH Toolbox Pain Intensity FF Age 18+ v2.0 Instrument are practices\n",
    "#So only the Pain Intensity instrument needed special coding attention \n",
    "#check your data and adjust if needed - note that subject and visit are variables we created locally \n",
    "#to merge with the data coming from a different local source (REDCap)\n",
    "#create the NDA structure for this special case\n",
    "#this structure doesnt get 'sent through crosswalk' so any code that is in python column wont get executed\n",
    "\n",
    "inst_i='NIH Toolbox Pain Intensity FF Age 18+ v2.0'\n",
    "#most of the rows contain duplicated information...only need to know the PIN once, for example, not once for each item response\n",
    "# so values in the response column need to be pivoted and then merged with the rest of the data, \n",
    "paindata=rawdata.loc[rawdata.Inst==inst_i][['PIN','subject','Inst','visit','ItemID','Position',\n",
    "        'subjectkey','src_subject_id','interview_age','interview_date','gender',\n",
    "        'Response','ResponseTime', 'SE', 'Score', 'TScore','Theta','Assessment Name']]\n",
    "paindata.ItemID = paindata.ItemID.str.lower().str.replace('-','_').str.replace('(','_').str.replace(')','_')\n",
    "inst = paindata.pivot(index='PIN', columns='ItemID', values='Score').reset_index()\n",
    "meta = paindata.drop_duplicates(subset=['PIN', 'visit'])\n",
    "\n",
    "#meta['Inst']=inst_i\n",
    "painreshaped = pd.merge(meta, inst, on='PIN', how='inner').drop(columns={'subject','visit','PIN'})\n",
    "crosswalk_subset=crosswalk.loc[crosswalk['Inst']==inst_i]\n",
    "crosswalk_subset.reset_index(inplace=True)\n",
    "cwlist=list(crosswalk_subset['hcp_variable_upload']) #these should all correspond with the nda_element names in this structure\n",
    "\n",
    "#several dummy vars for required vars - normally these would have placeholders in the meta (scores) files but \n",
    "#since this particular instrument only exists in the raw data, we have to explicitly create place holders\n",
    "painreshaped['pssr8_12_10']=painreshaped.pssr8_12_10.round().fillna(-9999).astype(int).astype(str).str.replace('-9999','')\n",
    "painreshaped['nih_tlbx_agegencsc']=999\n",
    "painreshaped['nih_tlbx_rawscore']=999\n",
    "painreshaped['nih_tlbx_tscore']=999\n",
    "painreshaped['nih_tlbx_se']=999\n",
    "painreshaped['nih_tlbx_theta']=999\n",
    "painreshaped['respondent']='self'\n",
    "painreshaped['version_form']=painreshaped['Inst']\n",
    "painreshaped['fneproc']=painreshaped['Assessment Name'].str.replace('Assessment ','')\n",
    "painreshaped['comqother']=painreshaped['respondent']\n",
    "\n",
    "#painreshaped['version_form']=painreshaped.Inst\n",
    "#+','+painreshaped['Assessment Name']\n",
    "\n",
    "reshapedslim=painreshaped[ndarlist+cwlist]\n",
    "\n",
    "#the data2struct function only uses the crosswalk to get the structure name and number for the header of dout\n",
    "#dout is otherwise ready to go and data2structure just writes it to a file in the specified location\n",
    "data2struct(patho=pathout,dout=reshapedslim,crosssub=crosswalk_subset,study=hcp_studystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING!!! Cognition Composite Scores: Crosswalk expects 17 elements, but only found 13 in the prepared data\n"
     ]
    }
   ],
   "source": [
    "# Another special case is for Cognition Composite scores all v1.1 - going to cogcomp01 structure at the NDA- \n",
    "# Cog comp is special for several reason...it doesnt have corresponding entries in the raw data because\n",
    "# it represents a summary across instruments in the Cognitive domain.  Even so, 4 cog comp 'instruments' are going to \n",
    "# a single NDA structure.  Each of these insturments has a version number and an assessmen\n",
    "# This was mapped before Leo agreed to accept data by NIH Toolbox Instrument name (pivot by Inst)\n",
    "# keeping this special case coding in for posterity and to shed light on one type of merge he must do on his end\n",
    "# and the fact that this special situation is not yet being addressed (unless they can take multiple rows per person)\n",
    "# Note that this structure illustrates the versioning problem when merging several NIH Toolbox Instruments together\n",
    "# onto the same row\n",
    "# Instruments are being mapped to the same # buckets\n",
    "# One of the main issues that will hopefully be resolved by teleconference 3/23 is how the NDA is keeping track of \n",
    "# several instruments (with different versions) getting mapped to the same rows in a structure\n",
    "# when it comes to NIH toolbox data\n",
    "\n",
    "#HCP-EP note: We did not have the variable \"National Percentile (age adjusted)\", therefore was removed from this block\n",
    "\n",
    "cogcompdata=scordata.loc[scordata.Inst.str.contains('Cognition')==True][['PIN','Language',\n",
    "    'Assessment Name','Inst',  'Uncorrected Standard Score', 'Age-Corrected Standard Score', #'National Percentile (age adjusted)'\n",
    "    'Fully-Corrected T-score']+ndarlist]\n",
    "\n",
    "#initialize prefix\n",
    "cogcompdata['varprefix']='test'\n",
    "cogcompdata.loc[cogcompdata.Inst=='Cognition Crystallized Composite v1.1','varprefix']='nih_crystalcogcomp_'\n",
    "cogcompdata.loc[cogcompdata.Inst=='Cognition Early Childhood Composite v1.1','varprefix']='nih_eccogcomp_'\n",
    "cogcompdata.loc[cogcompdata.Inst=='Cognition Fluid Composite v1.1','varprefix']='nih_fluidcogcomp_'\n",
    "cogcompdata.loc[cogcompdata.Inst=='Cognition Total Composite Score v1.1','varprefix']='nih_totalcogcomp_'\n",
    "\n",
    "#pivot the vars of interest by varprefix and rename\n",
    "uncorr=cogcompdata.pivot(index='PIN',columns='varprefix',values='Uncorrected Standard Score')\n",
    "for col in uncorr.columns.values:\n",
    "    uncorr=uncorr.rename(columns={col:col+\"unadjusted\"})\n",
    "ageadj=cogcompdata.pivot(index='PIN',columns='varprefix',values='Age-Corrected Standard Score')\n",
    "for col in ageadj.columns.values:\n",
    "    ageadj=ageadj.rename(columns={col:col+\"ageadj\"})\n",
    "#npage=cogcompdata.pivot(index='PIN',columns='varprefix',values='National Percentile (age adjusted)')\n",
    "#for col in npage.columns.values:\n",
    "  #  npage=npage.rename(columns={col:col+\"np_ageadj\"})\n",
    "\n",
    "#put them together\n",
    "cogcompreshape=pd.concat([uncorr,ageadj],axis=1)\n",
    "\n",
    "#hijacking what is the same for all four instruments\n",
    "meta=cogcompdata[['PIN','Language']+ndarlist].drop_duplicates(subset={'PIN'})\n",
    "\n",
    "#all the data in place\n",
    "cogcompreshape=pd.merge(meta,cogcompreshape,on='PIN',how='inner')\n",
    "\n",
    "# Now grabbing version and assessment info for version_form\n",
    "# initial attempt to capture the version failed ...they got mapped to raw scores \n",
    "# and failed validation \n",
    "# per email, all of this information will go to the 'version_form' variable.\n",
    "meta2=cogcompdata[['PIN','Inst','Assessment Name']].drop_duplicates(subset={'PIN','Inst'})\n",
    "meta2['Inst,Assessment Name']=meta2['Inst']+','+meta2['Assessment Name']\n",
    "meta3=meta2.pivot(index='PIN',columns='Inst',values='Inst,Assessment Name')\n",
    "#this will only work until there are more than one versions of the composites in the data\n",
    "#need to make it more flexible so that there are 4 possible instruments (whatever version they may be)\n",
    "meta3['version_monster']=meta3['Cognition Crystallized Composite v1.1']+';'+meta3['Cognition Early Childhood Composite v1.1']+';'+meta3['Cognition Fluid Composite v1.1']+';'+meta3['Cognition Total Composite Score v1.1']\n",
    "\n",
    "meta3['nih_crystalcogcomp']=meta3['Cognition Crystallized Composite v1.1']\n",
    "meta3['nih_eccogcomp']=meta3['Cognition Early Childhood Composite v1.1']\n",
    "meta3['nih_fluidcogcomp']=meta3['Cognition Fluid Composite v1.1']\n",
    "meta3['nih_totalcogcomp']=meta3['Cognition Total Composite Score v1.1']\n",
    "\n",
    "##for i in meta3.columns.to_list();  \n",
    "#meta3=meta3['version_form'].reset_index()\n",
    "\n",
    "cogcompreshape=pd.merge(cogcompreshape,meta3,on='PIN',how='inner')\n",
    "#cogcompreshape.columns\n",
    "inst_i='Cognition Composite Scores'  #one instrument here...is merging of four instruments there\n",
    "\n",
    "#crosswalk_subset=crosswalk.loc[crosswalk.Inst==inst_i]\n",
    "#cwlist=list(crosswalk_subset['hcp_variable_upload']) #these should all correspond with the nda_element names in this structure\n",
    "#reshapedslim=cogcompreshape[ndarlist+cwlist]\n",
    "#cogcompreshape[cwlist]\n",
    "#the data2struct function only uses the crosswalk to get the structure name and number for the header of dout\n",
    "#dout is otherwise ready to go and data2structure just writes it to a file in the specified location\n",
    "#data2struct(patho=pathout,dout=reshapedslim,crosssub=crosswalk_subset,study=hcp_studystr)\n",
    "\n",
    "\n",
    "sendthroughcrosswalk(pathout,cogcompreshape,inst_i,crosswalk,studystr=hcp_studystr,verbose='No',debug='Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING!!! NIH Toolbox Dimensional Change Card Sort Test Ages 3-7 v2.1: Crosswalk expects 62 elements, but only found 9 in the prepared data\n"
     ]
    }
   ],
   "source": [
    "##test area for testing individual instruments\n",
    "inst_i='NIH Toolbox Dimensional Change Card Sort Test Ages 3-7 v2.1'\n",
    "items=rawdata.loc[rawdata.Inst==inst_i][['PIN','subject','Inst','visit','ItemID','Position',\n",
    "   'subjectkey','src_subject_id','interview_age','interview_date','gender',\n",
    "   'Score','ResponseTime']]# not these..., 'SE', 'Score', 'TScore','Theta']]\n",
    "items.ItemID = items.ItemID.str.lower().str.replace('-','_').str.replace('(','_').str.replace(')','_').str.replace(' ','_')\n",
    "inst=items.pivot(index='PIN',columns='ItemID',values='Score').reset_index()\n",
    "meta=items.drop_duplicates(subset=['PIN','visit'])\n",
    "instreshaped = pd.merge(meta, inst, on='PIN', how='inner').drop(columns={'subject', 'visit','Inst'})\n",
    "items2=scordata.loc[scordata.Inst==inst_i][scorlist]\n",
    "\n",
    "instreshapedfull=pd.merge(instreshaped,items2,on='PIN',how='inner')\n",
    "instreshapedfull['version_monster']=instreshapedfull['Inst']+','+instreshapedfull['Assessment Name']\n",
    "if 'Parent' in inst_i:\n",
    "    instreshapedfull['respondent']='parent'\n",
    "else:\n",
    "    instreshapedfull['respondent']='self'\n",
    "sendthroughcrosswalk(pathout,instreshapedfull, inst_i, crosswalk,studystr=hcp_studystr,verbose='No',debug='Yes')\n",
    "#for i in instreshapedfull.columns:\n",
    "#    print(i)\n",
    "#meta.columns\n",
    "##items2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visual Acuity instruments, for example, have an unknown and variable number of \n",
    "#repeated items at different 'positions' which would require a double transpose into a single instrument 'row' per person.\n",
    "#NDA mapped all the different positions we saw in our data (see placeholders in crosswalk), but will assuredly \n",
    "#not have all of your positions.  For visual acuity, the scores matter more than the individual items, however, \n",
    "#so we opted to only send scores for this particular instrument.  Feel free to extend the specialty code below to \n",
    "#accommodate item level instrument for visual acuity.  \n",
    "#Visual Acuity items not yet mapped - come back to it if possible before the release otherwise omit item levels this release\n",
    "#scores are mapped in the first special case above.\n",
    "\n",
    "\n",
    "#Last special Case is for Visual Acuity, which needs double pivot because of repeat items at different positions\n",
    "#This special case not yet mapped by NDA - so don't run, but will look something like this\n",
    "#special case for instruments with \"Visual Acuity\" in their titles, which have dup inst/itemid at diff positions\n",
    "#for i in scordata.Inst.unique():\n",
    "#    if i in rawdata.Inst.unique():\n",
    "#        inst_i=i\n",
    "#        if \"Visual Acuity\" in inst_i:\n",
    "#            print('Processing ' + inst_i + '...')\n",
    "#                items=rawdata.loc[rawdata.Inst.str.contains('Visual Acuity')][['PIN','subject','Inst',\n",
    "#                   'gender','visit','ItemID','Position','Response','Score']]\n",
    "#                items.ItemID = items.ItemID.str.lower()\n",
    "#               items['dup_number']=items.groupby(['PIN','ItemID']).cumcount()+1\n",
    "#               items['ItemID_Dup']=items.ItemID.str.replace('|', '_') + '_P'+items.dup_number.astype(str)\n",
    "#               inst=items.pivot(index='PIN',columns='ItemID_Dup',values='Score')\n",
    "#               meta = items.drop_duplicates(subset=['PIN', 'visit'])[['Inst', 'PIN', \n",
    "#                                                              'subject', 'visit']]\n",
    "#               instreshaped = pd.merge(meta, inst, on='PIN', how='inner')\n",
    "#               items2 = scordata.loc[scordata.Inst == inst_i]\n",
    "#               instreshapedfull = pd.merge(instreshaped, items2, on='PIN', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now validate all of these files by calling the OS from within this notebook (assuming you are using linux) to run the NDA validator on your command line.  Alternatively, you could just navigate to your terminal and\n",
    "execute the following for loop .  \n",
    "\n",
    "for var in pathout/*.csv; do vtcmd $var; done\n",
    "\n",
    "Either option requires that you have downloaded and installed https://github.com/NDAR/nda-tools python package\n",
    "per instructions.  I installed vtcmd in my home directory, which set a couple defaults in place., such as the location of validation results. To have the output of the validation sent to a more meaningful location than than the default, I opened the /home/petra/.NDATools/settings.cfg file, and  \n",
    "changed the line under [Files] that says 'validation_results = NDAValidationResults' to a better place (perhaps 'pathout').  Example, mine now says \n",
    "validation_results = /home/petra/UbWinSharedSpace1/ccf-nda-behavioral/PycharmToolbox/Ipad2NDA_withCrosswalk/NIHToolbox2NDA/NDAValidationResults\n",
    "\n",
    "so that the prepped structures directory and the NDAValidationResults Directory are right next to one another.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you had an error in the validation, your likely course of action is to debug the python code in the the crosswalk. Here are some unix commands to help filter through common issues in the Validation results:  \n",
    "\n",
    "Find all the not integer warnings:\n",
    "grep notInteger /home/petra/NDAValidationResults/* > Notintegerwarnings\n",
    "\n",
    "Find all the invalid range warnings \n",
    "grep \"invalid\" NDAValidationResults/* | cut -d ',' -f 1,6\n",
    "\n",
    "Cat all of the validation results together so you can see them all at once\n",
    "cat NDAValidationResults/validation*.csv > NDAValidationResults/Allvalidations.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
